{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACCIÓN DE DATOS</br>\n",
    "Lectura de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"\\\\Datasets\\\\\"\n",
    "files = glob.glob(path + \"/*precios*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\eliza\\\\Desktop\\\\PI01_Data04\\\\app\\\\Datasets\\\\'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path): \n",
    "    \"\"\"Funcion para leer cada df q vienen en distintos formatos, leer varias hojas de un xlsx \"\"\"\n",
    "    for i in path:\n",
    "        ext = os.path.splitext(i)[-1].lower() #deja solo las extensiones\n",
    "        if ext=='.xlsx':\n",
    "            xls = pd.ExcelFile(i)\n",
    "            sheets=xls.sheet_names\n",
    "            if len(sheets)==1:\n",
    "                df=pd.read_excel(i)\n",
    "                return df\n",
    "            elif len(sheets)==2:\n",
    "                df1=pd.read_excel(i,sheet_name=0).assign(semana=sheets[0])\n",
    "                df2=pd.read_excel(i,sheet_name=1).assign(semana=sheets[1])\n",
    "                return df1, df2\n",
    "            else:\n",
    "                print('Archivo Excel con mas de dos sheets')\n",
    "        elif ext=='.csv':\n",
    "            df=pd.read_csv(i,sep=',',encoding='utf-16-le').assign(semana=os.path.basename(i).split('.')[0])\n",
    "            return df\n",
    "\n",
    "        elif ext=='.txt':\n",
    "            df=pd.read_csv(i, sep='|').assign(semana=os.path.basename(i).split('.')[0])\n",
    "            return df\n",
    "\n",
    "        elif ext=='.json':\n",
    "            df=pd.read_json(i).assign(semana=os.path.basename(i).split('.')[0])\n",
    "            return df\n",
    "\n",
    "        elif ext=='.parquet':\n",
    "            df=pd.read_parquet(i)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"I just can't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de archivo\n",
    "producto = glob.glob(path + \"/producto.parquet\")\n",
    "producto = read_file(producto) #con funcion read_file definida arriba\n",
    "\n",
    "sucursal = glob.glob(path + \"/*sucursal*\")\n",
    "sucursal = pd.read_csv(sucursal[0])\n",
    "\n",
    "precio13 = glob.glob(path + \"/*precios_semana_20200413*\")\n",
    "precio13 = read_file(precio13)\n",
    "\n",
    "precio03 = glob.glob(path + \"/*precios_semana_20200503*\")\n",
    "precio03 = read_file(precio03)\n",
    "\n",
    "precio18 = glob.glob(path + \"/*precios_semana_20200518*\")\n",
    "precio18 = read_file(precio18)\n",
    "\n",
    "precios19 = pd.read_excel(files[0],sheet_name=1).assign(semana=\"precios_semanas_20200419\")\n",
    "precios26 = pd.read_excel(files[0], sheet_name=0).assign(semana=\"precios_semanas_20200426\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación y limpieza de df: producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0.000000\n",
       "marca            0.002776\n",
       "nombre           0.002776\n",
       "presentacion     0.002776\n",
       "categoria1      99.994447\n",
       "categoria2      99.994447\n",
       "categoria3      99.994447\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veamos los nulos\n",
    "producto.isna().sum()*100/72038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000001663</td>\n",
       "      <td>LA ANÓNIMA</td>\n",
       "      <td>Radicheta Atada La Anonima 1 Un</td>\n",
       "      <td>1.0 un</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       marca                           nombre presentacion\n",
       "0  0000000001663  LA ANÓNIMA  Radicheta Atada La Anonima 1 Un       1.0 un"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se eliminaran las columnas categoria ya que no aportan informacion relevante\n",
    "#inplace=True se usa dependiendo de si queremos hacer cambios al df original o no.\n",
    "producto.drop(columns=['categoria1','categoria2','categoria3'], inplace=True)\n",
    "producto.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marca', 'nombre', 'presentacion', 'producto_id'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizando id por producto_id\n",
    "producto[\"producto_id\"] = producto[\"id\"]\n",
    "producto.drop(columns=[\"id\"], inplace=True)\n",
    "producto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasDups(df):\n",
    "    \"\"\"Cosas básicas: remover duplicados y nulos\"\"\"#servira para load demas dfs\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "producto = nasDups(producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitProd(df): #elimina el  - para luego darle tipo de dato a float\n",
    "    \"\"\"Algunos productos tenian hardcodeada la sucursal. Removemos esa porcion del string y nos quedamos \n",
    "       unicamente con el codigo de producto (12-13 char)\"\"\"\n",
    "\n",
    "    df.producto_id = df.producto_id.str.split('-').str[-1]\n",
    "    return df\n",
    "producto = splitProd(producto)\n",
    "producto.drop_duplicates(subset=['producto_id'], inplace=True) #eliminando duplicados en la columna producto.id ya que seran PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precio         float64\n",
       "producto_id     object\n",
       "sucursal_id     object\n",
       "semana          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precio13.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "producto.marca=producto.marca.astype(\"string\")\n",
    "producto.nombre=producto.nombre.astype(\"string\")\n",
    "producto.presentacion=producto.presentacion.astype(\"string\")\n",
    "producto.producto_id=producto.producto_id.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marca           string[python]\n",
       "nombre          string[python]\n",
       "presentacion    string[python]\n",
       "producto_id              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producto.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformacion y limpieza de datos de df: de sucursal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comercioId', 'banderaId', 'banderaDescripcion', 'comercioRazonSocial',\n",
       "       'provincia', 'localidad', 'direccion', 'lat', 'lng', 'sucursalNombre',\n",
       "       'sucursalTipo', 'sucursal_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizando id por sucursal_id\n",
    "sucursal[\"sucursal_id\"] = sucursal[\"id\"]\n",
    "sucursal.drop(columns=[\"id\"], inplace=True)\n",
    "sucursal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sucursal = nasDups(sucursal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unDate(df):\n",
    "    \n",
    "    def unDateSeries(x):\n",
    "        \"\"\"read_excel me trae algunas sucursal_id como si fueran datetime. Esta funcion toma elementos de una serie, \n",
    "           chequea si son datetime y en caso de serlo, los convierte a str con el formato acorde al orden de identificadores de sucursal\"\"\"\n",
    "       \n",
    "        if isinstance(x,datetime):\n",
    "            x=x.strftime(\"%#d-%#m-%Y\")\n",
    "        return x\n",
    "\n",
    "    df.sucursal_id = df.sucursal_id.apply(unDateSeries)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando: eliminando los 00:00:00 de sucursal_id\n",
    "def delete00(df):\n",
    "    if df.sucursal_id.dtype != \"str\":\n",
    "            df.sucursal_id = df.sucursal_id.astype('string')\n",
    "    df['sucursal_id'] = df['sucursal_id'].apply(lambda x: x.split(' ')[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sucursal = delete00(sucursal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_sucu(sucursal):\n",
    "    sucursal.sucursal_id=sucursal.sucursal_id.astype('string')    \n",
    "    sucursal.comercioId = sucursal.comercioId.astype(int)\n",
    "    sucursal.banderaId = sucursal.banderaId.astype(int)\n",
    "    sucursal.banderaDescripcion = sucursal.banderaDescripcion.astype('string')\n",
    "    sucursal.comercioRazonSocial = sucursal.comercioRazonSocial.astype('string')\n",
    "    sucursal.provincia = sucursal.provincia.astype('string')\n",
    "    sucursal.localidad = sucursal.localidad.astype('string')\n",
    "    sucursal.direccion = sucursal.direccion.astype('string')\n",
    "    sucursal.sucursalNombre = sucursal.sucursalNombre.astype('string')\n",
    "    sucursal.sucursalTipo = sucursal.sucursalTipo.astype('string')\n",
    "    sucursal.columns = sucursal.columns.str.lower()\n",
    "    return sucursal\n",
    "sucursal = type_sucu(sucursal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comercioid                      int32\n",
       "banderaid                       int32\n",
       "banderadescripcion     string[python]\n",
       "comerciorazonsocial    string[python]\n",
       "provincia              string[python]\n",
       "localidad              string[python]\n",
       "direccion              string[python]\n",
       "lat                           float64\n",
       "lng                           float64\n",
       "sucursalnombre         string[python]\n",
       "sucursaltipo           string[python]\n",
       "sucursal_id            string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sucursal.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranformación, limpieza, normalizacion dataframe: precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplico la funcion para eliminar nulos y duplicados\n",
    "precio13 = nasDups(precio13)\n",
    "precio03 = nasDups(precio03)\n",
    "precio18 = nasDups(precio18)\n",
    "precios19 = nasDups(precios19)\n",
    "precios26 = nasDups(precios26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicar la funcion para quitar el caracter especial - y tomar solo numeros\n",
    "precio13 = splitProd(precio13)\n",
    "precio03 = splitProd(precio03)\n",
    "precio18 = splitProd(precio18)\n",
    "precios19 = splitProd(precios19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para quitar 00:00:00 y tomar solo los demas numeros correctos\n",
    "precio13 = delete00(precio13)\n",
    "precio03 = delete00(precio03)\n",
    "precio18 = delete00(precio18)\n",
    "precios19 = delete00(precios19)\n",
    "precios26 = delete00(precios26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracter(df):\n",
    "    if df.precio.dtype != \"float\":\n",
    "        \"\"\"Algunos precios llegan con un string vacio en vez de nulo. Los convertimos a None para removerlos despues. \n",
    "           A los que tienen valores, los convertimos a float\"\"\"\n",
    "        try:\n",
    "            df.precio = df.precio.apply(lambda x: None if x == '' else x)\n",
    "            df.precio = df.precio.astype(float)\n",
    "        except:\n",
    "            print(\"Error type precios\")\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignación de los tipos de datos de los valores de los dfs: precios\n",
    "#algunos ya estan solo los q faltan\n",
    "def type_precios(df):\n",
    "    df.semana = df.semana.astype(\"string\")\n",
    "    df.sucursal_id = df.sucursal_id.astype(\"string\")\n",
    "    df.producto_id = df.producto_id.astype(\"int64\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplico la funcion anterior\n",
    "precio13 = caracter(precio13)\n",
    "precio03 = caracter(precio03)\n",
    "precio18 = caracter(precio18)\n",
    "precios19 = caracter(precios19)\n",
    "precios26 = caracter(precios26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asigno el tipo de dato para df: precio\n",
    "precio13 = type_precios(precio13)\n",
    "precio03 = type_precios(precio03)\n",
    "precio18 = type_precios(precio18)\n",
    "precios19 = type_precios(precios19)\n",
    "precios26 = type_precios(precios26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precio                float64\n",
       "producto_id             int64\n",
       "sucursal_id    string[python]\n",
       "semana         string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios26.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar los dfs de los todos los precios con concat\n",
    "precios = pd.concat([precio13, precio03, precio18, precios19, precios26]) \n",
    "#aplico los tipos de datos\n",
    "precios = type_precios(precios)\n",
    "#dropeo algunos duplicados\n",
    "precios = precios.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precio                float64\n",
       "producto_id             int64\n",
       "sucursal_id    string[python]\n",
       "semana         string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voy a unir en un solo df *1ero* en *Python* para luego levantar una API en docker, luego cargar los datos a *MySql* con foreign keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el inner join\n",
    "producto_precios = pd.merge(producto, precios, on='producto_id', how='inner')\n",
    "df = pd.merge(producto_precios, sucursal, on='sucursal_id', how='inner')\n",
    "#exportamos para asi poder leer desde fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redusco ala 4 ta parte de os registors ya q pesa demasiado para suboir gratuitamente a github\n",
    "df = df.iloc[::4]\n",
    "df.shape\n",
    "df.to_csv(r'Datasets/df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promedio de precio': 172.97052380952383}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query 1: Promedio de precio para sucursal_id '9-1-688': 202.56114869626498\n",
    "def promedio_precio(sucursal_id:str):\n",
    "    precio_promedio1 = df[df['sucursal_id'] == sucursal_id]['precio'].mean()\n",
    "    return {'promedio de precio': precio_promedio1}\n",
    "\n",
    "promedio_precio('2-1-014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precio promedio de la marca DOVE:': 1934.7378714249558}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query 2: calcular el precio promedio de la marca DOVE\n",
    "def precio_promedio_marca(marca:str):\n",
    "    precio_promedio_marca = df[df['marca'] == marca]['precio'].mean()\n",
    "    return {\"precio promedio de la marca DOVE:\": precio_promedio_marca}\n",
    "precio_promedio_marca('DOVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producto más vendido': 7791290010482, 'Cantidad de veces que se vendió': 51}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query3: cantidad de veces que se vendio el producto_id mas vendido de la sucursaltipo 'Supermercado'\n",
    "def producto_mas_vendido(Supermercado:str):\n",
    "    supermercado_df = df[(df['sucursaltipo']==Supermercado)]\n",
    "    producto_mas_vendido = supermercado_df['producto_id'].value_counts().idxmax()\n",
    "    cantidad_mas_vendida = supermercado_df['producto_id'].value_counts().max()\n",
    "    \n",
    "    return {'producto más vendido': producto_mas_vendido,\n",
    "            'Cantidad de veces que se vendió':cantidad_mas_vendida}\n",
    "\n",
    "producto_mas_vendido('Supermercado')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c01cf4a2356650b355da24661dd0626acaa1665bc8e66dede1d15fa072b6b8b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
